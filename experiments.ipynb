{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uploaded_files\\\\t1.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(\"uploaded_files\",\"t1.txt\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uploaded_files\\\\user_1\\\\t1.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.path.join('uploaded_files','user_1'),'t1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shree/njagatap'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/n\".join(['shree','jagatap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uploaded\\\\user_1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('uploaded','user_{i}'.format(i=count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=None\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = 3\n",
    "print(a)\n",
    "\n",
    "def h():\n",
    "    b=2\n",
    "    global a\n",
    "    print(b)\n",
    "    a=b\n",
    "    print(a)\n",
    "h()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 10\n",
    "\n",
    "\n",
    "def hello():\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PDFLoader' from 'langchain.document_loaders' (d:\\GENERATIVE-AI\\007_Projects\\002_Chat_With_Multiple_Dcoumnet\\qa_venv\\lib\\site-packages\\langchain\\document_loaders\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DirectoryLoader, TextLoader, PDFLoader, CSVLoader\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'PDFLoader' from 'langchain.document_loaders' (d:\\GENERATIVE-AI\\007_Projects\\002_Chat_With_Multiple_Dcoumnet\\qa_venv\\lib\\site-packages\\langchain\\document_loaders\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, TextLoader, PDFLoader, CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "def pdf_loader(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def csv_loader(file_path):\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loader(file_path):\n",
    "    if file_path.endswith('.txt'):\n",
    "        return text_loader(file_path)\n",
    "    elif file_path.endswith('.pdf'):\n",
    "        return pdf_loader(file_path)\n",
    "    elif file_path.endswith('.csv'):\n",
    "        return csv_loader(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for filename in os.listdir(\"uploaded_files\"):\n",
    "    file_path = os.path.join(\"uploaded_files\", filename)\n",
    "    documents.append(custom_loader(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Recommended Open -Source/Unpaid LLM Models  \\n1. BLOOM by BigScience  \\n• Description : BLOOM (BigScience Large Open -science Open -access Multilingual \\nLanguage Model) is a multilingual model designed to perform well across various \\nlanguages and tasks.  \\n• SuperGLUE Score : ~78.5  \\n• MMLU Score : ~70.0  \\n• Strengths : Multilingual capabilities, open -access nature, strong performance in \\nsummarization tasks.  \\n• Link : BLOOM on Hugging Face  \\n2. GPT -NeoX by EleutherAI  \\n• Description : GPT -NeoX is an open -source LLM developed by EleutherAI, known \\nfor its performance in generating human -like text.  \\n• SuperGLUE Score : ~72.3  \\n• MMLU Score : ~63.2  \\n• Strengths : Good performance on various NLP tasks, strong community support, \\nscalability.  \\n• Link : GPT -NeoX on Hugging Face  \\n3. GPT -J by EleutherAI  \\n• Description : GPT -J is an open -source model from EleutherAI with strong \\nperformance in various language tasks.  \\n• SuperGLUE Score : ~67.3  \\n• MMLU Score : ~55.6  \\n• Strengths : Strong performance in generating coherent text, cost -effective.  \\n• Link : GPT -J on Hugging Face  \\n4. T5 by Google  \\n• Description : T5 (Text -to-Text Transfer Transformer) is a versatile model that can be \\nfine-tuned for various NLP tasks, including summarization.  \\n• SuperGLUE Score : ~89.3 (for T5 -XXL, the largest variant)  \\n• Strengths : High performance, versatility in handling different tasks, effective in \\nsummarization.  \\n• Link : T5 on Hugging Face  \\n6. RoBERTa by Facebook AI  \\n• Description : RoBERTa is an optimized version of BERT.  \\n• SuperGLUE Score : ~89.9 (for RoBERTa -large)  \\n• Link : RoBERTa on Hugging Face  \\n7. ALBERT by Google Research  \\n• Description : ALBERT is a smaller and more efficient version of BERT.  \\n• SuperGLUE Score : ~89.3 (for ALBERT -xxlarge)  \\n• Link : ALBERT on Hugging Face  \\n8. FLAN -T5 by Google Research  • Description : FLAN -T5 is a family of models trained on a mixture of natural language \\nunderstanding and generation tasks.  \\n• SuperGLUE Score : ~89.3 (for FLAN -T5-XXL)  \\n• Link : FLAN -T5 on Hugging Face  \\n \\nAnalysis  \\n• Performance : T5,RoBERTa,ALBERT,  especially the larger variants, offers the \\nhighest performance but requires more computational resources. BLOOM and GPT -\\nNeoX provide a balance of performance and accessibility.  \\n• Cost and Availability : All recommended models are free and open -source, ensuring \\nno cost for API usage. Computational costs can be managed by using efficient cloud \\nservices or local deployment.  \\n• Suitability for Summarization : T5 and BLOOM are particularly strong in text \\ngeneration and summarization tasks, making them ideal for our use case.  \\nConclusion  \\nFor the educational application aimed at summarizing student performance, the following \\nmodels are recommended based on their performance, cost -effectiveness, and suitability:  \\n1. T5 \\n2. RoBERTa  \\n3. ALBERT  \\n \\nRecommended Cloud  \\nhttps://github.com/shreedhar13/OpenLLM  \\nCloud – K8S , BentoCloud  \\n ', 'Shreedhar Sanjay Jagatap  \\nshreedharjagatap2002 @gmail.com | +91 9663659354  \\nhttps://github.com/shreedhar13  | https://www.linkedin.com/in/shreedhar13/  \\nLanguages: C, Python, SQL  \\nTechnologies & Tools: Advance  Excel, PowerBI , MySQL,  Machine Learning , Deep Learning , NLP, LLM’s , LangChain, \\nStatistic al Analysis , Mathamatics , Flask . \\n \\nWork Experience  \\nAltizon , Pune  Jun 2023 – Sep 2023  \\nData Science  (INTERN)  \\n• Conducted extensive data preprocessing, including data cleaning, normalization, and feature engineering.  \\n• Performed rigorous  data analysis and visualization using Pandas, NumPy, Matplotlib  and Seaborn.  Utilized Python \\nand key ML libraries such as TensorFlow, Keras, and Scikit -learn  for various  regression and classification , ANN, CNN  \\nand RNN  model building . \\n• Performed hyperparameter tuning, cross -validation, and model optimization to enhance performance . \\n• Collaborated with cross -functional teams to align models with business needs and objectives  \\n• Maintained Data Pipeline  and ETL Process es. \\nMentorness, Gujarat  May 2024 – July 2024  \\nData Analytics (INTERN)  \\n• Involved in collecting, analyzing, and interpreting data to help organizations make decision.  \\n• Performed EDA (Explorato ry Data Analy sis) using Excel, SQl, Python, Power BI . \\n• Utilized MS Power Point and Word for report building  \\n \\nEducation  \\nVTU Karnataka  Dec 2020 - May 2024  \\nB.E. in Computer Science and Engineering  CGPA: 8.84/10 \\nRelevant Coursework: Object Oriented Programming (OOP’s) , Database  Management System , Discrete Maths, Data \\nStructures and Algorithms, Operating Systems, Computer Networks,  Cloud Computing, Artificial Intelligence and  Machine \\nLearning, Big Data Analytics , Internet Of Things , Unix/Linux Programming  \\nProject Work  \\n• Amazon Products Recommendation Engine  (Mar 2024): Implemented  Amazon product recommendation engine \\nutilizing both item -based and user -based collaborative filtering, increasing recommendation accuracy by 25%. \\nEnhanced user experience by providing personalized product suggestions, boosting user engagement by 30%. \\nImplemented algorithms to improve efficiency, reducing computation time by 20%.  \\n• Fassos Data Analysis Using SQL ( Mar 2024 ): Created dummy dataset by thinking of  real world scenario .Conducted \\ndata cleaning ,Preprocessing and then performed Analysis using SQL.  Analyze order patterns to optimize delivery \\nschedules and staffing  around 10% and Optimize ingredient usage to reduce waste and operational costs  50%.  \\n• TMDB Movie Recommendation System ( Apr 2024 ): Designed  TMDB movie recommendation system using  \\ncontent -based approach to suggest personalized movie options. Designed user -friendly web interface with Streamlit \\nframework. Deployed application on Render.com for robust accessibility and performance.  \\n• Anomaly Detection ( Dec 2023 ): Engineered  anomaly detection system using CNN and LSTM to identify unusual \\nactivities such as accidents and robberies, and to automatically alert emergency services. Achieved detection accuracy \\nof 92%, significantly improving response times. Enhanced system efficien cy by 15%.  \\n• Spam Message Filtering ( Oct 2023 ): Built and Deployed High -Precision Spam Detection Model. Applied all \\nsupervised machine learning classification algoruthms  and ensemble techniques  to get better model .Minimized false \\npositives by 90% through rigorous feature engineering and hyperparameter tuning processes with 98% accuracy and \\n100% precision score in spam detection . \\n• Bank Loan Analysis Dashboard  (Nov 2023 ): Created dynamic and user -friendly PowerBI dashboard to provide \\ndetailed insights into loan data, borrower profiles, and loan performance metrics.Dashboard integrates various \\nvisualizations and interactive elements to facilitate comprehensive data analysis. Supporting informed decision -making \\nand improving the overall loan management process by 50%.  \\n \\nAwards and Certificates  \\n• Google Data Analytics Specialization (Coursera)  \\n• Data Science And Machine Learning Specialization (C ampus -X) \\nSkills  ']\n"
     ]
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shreedhar Sanjay Jagatap  \\nshreedharjagatap2002 @gmail.com | +91 9663659354  \\nhttps://github.com/shreedhar13  | https://www.linkedin.com/in/shreedhar13/  \\nLanguages: C, Python, SQL  \\nTechnologies & Tools: Advance  Excel, PowerBI , MySQL,  Machine Learning , Deep Learning , NLP, LLM’s , LangChain, \\nStatistic al Analysis , Mathamatics , Flask . \\n \\nWork Experience  \\nAltizon , Pune  Jun 2023 – Sep 2023  \\nData Science  (INTERN)  \\n• Conducted extensive data preprocessing, including data cleaning, normalization, and feature engineering.  \\n• Performed rigorous  data analysis and visualization using Pandas, NumPy, Matplotlib  and Seaborn.  Utilized Python \\nand key ML libraries such as TensorFlow, Keras, and Scikit -learn  for various  regression and classification , ANN, CNN  \\nand RNN  model building . \\n• Performed hyperparameter tuning, cross -validation, and model optimization to enhance performance . \\n• Collaborated with cross -functional teams to align models with business needs and objectives  \\n• Maintained Data Pipeline  and ETL Process es. \\nMentorness, Gujarat  May 2024 – July 2024  \\nData Analytics (INTERN)  \\n• Involved in collecting, analyzing, and interpreting data to help organizations make decision.  \\n• Performed EDA (Explorato ry Data Analy sis) using Excel, SQl, Python, Power BI . \\n• Utilized MS Power Point and Word for report building  \\n \\nEducation  \\nVTU Karnataka  Dec 2020 - May 2024  \\nB.E. in Computer Science and Engineering  CGPA: 8.84/10 \\nRelevant Coursework: Object Oriented Programming (OOP’s) , Database  Management System , Discrete Maths, Data \\nStructures and Algorithms, Operating Systems, Computer Networks,  Cloud Computing, Artificial Intelligence and  Machine \\nLearning, Big Data Analytics , Internet Of Things , Unix/Linux Programming  \\nProject Work  \\n• Amazon Products Recommendation Engine  (Mar 2024): Implemented  Amazon product recommendation engine',\n",
       " '• Collaborated with cross -functional teams to align models with business needs and objectives  \\n• Maintained Data Pipeline  and ETL Process es. \\nMentorness, Gujarat  May 2024 – July 2024  \\nData Analytics (INTERN)  \\n• Involved in collecting, analyzing, and interpreting data to help organizations make decision.  \\n• Performed EDA (Explorato ry Data Analy sis) using Excel, SQl, Python, Power BI . \\n• Utilized MS Power Point and Word for report building  \\n \\nEducation  \\nVTU Karnataka  Dec 2020 - May 2024  \\nB.E. in Computer Science and Engineering  CGPA: 8.84/10 \\nRelevant Coursework: Object Oriented Programming (OOP’s) , Database  Management System , Discrete Maths, Data \\nStructures and Algorithms, Operating Systems, Computer Networks,  Cloud Computing, Artificial Intelligence and  Machine \\nLearning, Big Data Analytics , Internet Of Things , Unix/Linux Programming  \\nProject Work  \\n• Amazon Products Recommendation Engine  (Mar 2024): Implemented  Amazon product recommendation engine \\nutilizing both item -based and user -based collaborative filtering, increasing recommendation accuracy by 25%. \\nEnhanced user experience by providing personalized product suggestions, boosting user engagement by 30%. \\nImplemented algorithms to improve efficiency, reducing computation time by 20%.  \\n• Fassos Data Analysis Using SQL ( Mar 2024 ): Created dummy dataset by thinking of  real world scenario .Conducted \\ndata cleaning ,Preprocessing and then performed Analysis using SQL.  Analyze order patterns to optimize delivery \\nschedules and staffing  around 10% and Optimize ingredient usage to reduce waste and operational costs  50%.  \\n• TMDB Movie Recommendation System ( Apr 2024 ): Designed  TMDB movie recommendation system using  \\ncontent -based approach to suggest personalized movie options. Designed user -friendly web interface with Streamlit \\nframework. Deployed application on Render.com for robust accessibility and performance.',\n",
       " 'utilizing both item -based and user -based collaborative filtering, increasing recommendation accuracy by 25%. \\nEnhanced user experience by providing personalized product suggestions, boosting user engagement by 30%. \\nImplemented algorithms to improve efficiency, reducing computation time by 20%.  \\n• Fassos Data Analysis Using SQL ( Mar 2024 ): Created dummy dataset by thinking of  real world scenario .Conducted \\ndata cleaning ,Preprocessing and then performed Analysis using SQL.  Analyze order patterns to optimize delivery \\nschedules and staffing  around 10% and Optimize ingredient usage to reduce waste and operational costs  50%.  \\n• TMDB Movie Recommendation System ( Apr 2024 ): Designed  TMDB movie recommendation system using  \\ncontent -based approach to suggest personalized movie options. Designed user -friendly web interface with Streamlit \\nframework. Deployed application on Render.com for robust accessibility and performance.  \\n• Anomaly Detection ( Dec 2023 ): Engineered  anomaly detection system using CNN and LSTM to identify unusual \\nactivities such as accidents and robberies, and to automatically alert emergency services. Achieved detection accuracy \\nof 92%, significantly improving response times. Enhanced system efficien cy by 15%.  \\n• Spam Message Filtering ( Oct 2023 ): Built and Deployed High -Precision Spam Detection Model. Applied all \\nsupervised machine learning classification algoruthms  and ensemble techniques  to get better model .Minimized false \\npositives by 90% through rigorous feature engineering and hyperparameter tuning processes with 98% accuracy and \\n100% precision score in spam detection . \\n• Bank Loan Analysis Dashboard  (Nov 2023 ): Created dynamic and user -friendly PowerBI dashboard to provide \\ndetailed insights into loan data, borrower profiles, and loan performance metrics.Dashboard integrates various \\nvisualizations and interactive elements to facilitate comprehensive data analysis. Supporting informed decision -making',\n",
       " 'activities such as accidents and robberies, and to automatically alert emergency services. Achieved detection accuracy \\nof 92%, significantly improving response times. Enhanced system efficien cy by 15%.  \\n• Spam Message Filtering ( Oct 2023 ): Built and Deployed High -Precision Spam Detection Model. Applied all \\nsupervised machine learning classification algoruthms  and ensemble techniques  to get better model .Minimized false \\npositives by 90% through rigorous feature engineering and hyperparameter tuning processes with 98% accuracy and \\n100% precision score in spam detection . \\n• Bank Loan Analysis Dashboard  (Nov 2023 ): Created dynamic and user -friendly PowerBI dashboard to provide \\ndetailed insights into loan data, borrower profiles, and loan performance metrics.Dashboard integrates various \\nvisualizations and interactive elements to facilitate comprehensive data analysis. Supporting informed decision -making \\nand improving the overall loan management process by 50%.  \\n \\nAwards and Certificates  \\n• Google Data Analytics Specialization (Coursera)  \\n• Data Science And Machine Learning Specialization (C ampus -X) \\nSkills']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Shreedhar Sanjay Jagatap  \\nshreedharjagatap2002 @gmail.com | +91 9663659354  \\nhttps://github.com/shreedhar13  | https://www.linkedin.com/in/shreedhar13/  \\nLanguages: C, Python, SQL  \\nTechnologies & Tools: Advance  Excel, PowerBI , MySQL,  Machine Learning , Deep Learning , NLP, LLM’s , LangChain, \\nStatistic al Analysis , Mathamatics , Flask . \\n \\nWork Experience  \\nAltizon , Pune  Jun 2023 – Sep 2023  \\nData Science  (INTERN)  \\n• Conducted extensive data preprocessing, including data cleaning, normalization, and feature engineering.  \\n• Performed rigorous  data analysis and visualization using Pandas, NumPy, Matplotlib  and Seaborn.  Utilized Python \\nand key ML libraries such as TensorFlow, Keras, and Scikit -learn  for various  regression and classification , ANN, CNN  \\nand RNN  model building . \\n• Performed hyperparameter tuning, cross -validation, and model optimization to enhance performance . \\n• Collaborated with cross -functional teams to align models with business needs and objectives  \\n• Maintained Data Pipeline  and ETL Process es. \\nMentorness, Gujarat  May 2024 – July 2024  \\nData Analytics (INTERN)  \\n• Involved in collecting, analyzing, and interpreting data to help organizations make decision.  \\n• Performed EDA (Explorato ry Data Analy sis) using Excel, SQl, Python, Power BI . \\n• Utilized MS Power Point and Word for report building  \\n \\nEducation  \\nVTU Karnataka  Dec 2020 - May 2024  \\nB.E. in Computer Science and Engineering  CGPA: 8.84/10 \\nRelevant Coursework: Object Oriented Programming (OOP’s) , Database  Management System , Discrete Maths, Data \\nStructures and Algorithms, Operating Systems, Computer Networks,  Cloud Computing, Artificial Intelligence and  Machine \\nLearning, Big Data Analytics , Internet Of Things , Unix/Linux Programming  \\nProject Work  \\n• Amazon Products Recommendation Engine  (Mar 2024): Implemented  Amazon product recommendation engine', '• Collaborated with cross -functional teams to align models with business needs and objectives  \\n• Maintained Data Pipeline  and ETL Process es. \\nMentorness, Gujarat  May 2024 – July 2024  \\nData Analytics (INTERN)  \\n• Involved in collecting, analyzing, and interpreting data to help organizations make decision.  \\n• Performed EDA (Explorato ry Data Analy sis) using Excel, SQl, Python, Power BI . \\n• Utilized MS Power Point and Word for report building  \\n \\nEducation  \\nVTU Karnataka  Dec 2020 - May 2024  \\nB.E. in Computer Science and Engineering  CGPA: 8.84/10 \\nRelevant Coursework: Object Oriented Programming (OOP’s) , Database  Management System , Discrete Maths, Data \\nStructures and Algorithms, Operating Systems, Computer Networks,  Cloud Computing, Artificial Intelligence and  Machine \\nLearning, Big Data Analytics , Internet Of Things , Unix/Linux Programming  \\nProject Work  \\n• Amazon Products Recommendation Engine  (Mar 2024): Implemented  Amazon product recommendation engine \\nutilizing both item -based and user -based collaborative filtering, increasing recommendation accuracy by 25%. \\nEnhanced user experience by providing personalized product suggestions, boosting user engagement by 30%. \\nImplemented algorithms to improve efficiency, reducing computation time by 20%.  \\n• Fassos Data Analysis Using SQL ( Mar 2024 ): Created dummy dataset by thinking of  real world scenario .Conducted \\ndata cleaning ,Preprocessing and then performed Analysis using SQL.  Analyze order patterns to optimize delivery \\nschedules and staffing  around 10% and Optimize ingredient usage to reduce waste and operational costs  50%.  \\n• TMDB Movie Recommendation System ( Apr 2024 ): Designed  TMDB movie recommendation system using  \\ncontent -based approach to suggest personalized movie options. Designed user -friendly web interface with Streamlit \\nframework. Deployed application on Render.com for robust accessibility and performance.', 'utilizing both item -based and user -based collaborative filtering, increasing recommendation accuracy by 25%. \\nEnhanced user experience by providing personalized product suggestions, boosting user engagement by 30%. \\nImplemented algorithms to improve efficiency, reducing computation time by 20%.  \\n• Fassos Data Analysis Using SQL ( Mar 2024 ): Created dummy dataset by thinking of  real world scenario .Conducted \\ndata cleaning ,Preprocessing and then performed Analysis using SQL.  Analyze order patterns to optimize delivery \\nschedules and staffing  around 10% and Optimize ingredient usage to reduce waste and operational costs  50%.  \\n• TMDB Movie Recommendation System ( Apr 2024 ): Designed  TMDB movie recommendation system using  \\ncontent -based approach to suggest personalized movie options. Designed user -friendly web interface with Streamlit \\nframework. Deployed application on Render.com for robust accessibility and performance.  \\n• Anomaly Detection ( Dec 2023 ): Engineered  anomaly detection system using CNN and LSTM to identify unusual \\nactivities such as accidents and robberies, and to automatically alert emergency services. Achieved detection accuracy \\nof 92%, significantly improving response times. Enhanced system efficien cy by 15%.  \\n• Spam Message Filtering ( Oct 2023 ): Built and Deployed High -Precision Spam Detection Model. Applied all \\nsupervised machine learning classification algoruthms  and ensemble techniques  to get better model .Minimized false \\npositives by 90% through rigorous feature engineering and hyperparameter tuning processes with 98% accuracy and \\n100% precision score in spam detection . \\n• Bank Loan Analysis Dashboard  (Nov 2023 ): Created dynamic and user -friendly PowerBI dashboard to provide \\ndetailed insights into loan data, borrower profiles, and loan performance metrics.Dashboard integrates various \\nvisualizations and interactive elements to facilitate comprehensive data analysis. Supporting informed decision -making', 'activities such as accidents and robberies, and to automatically alert emergency services. Achieved detection accuracy \\nof 92%, significantly improving response times. Enhanced system efficien cy by 15%.  \\n• Spam Message Filtering ( Oct 2023 ): Built and Deployed High -Precision Spam Detection Model. Applied all \\nsupervised machine learning classification algoruthms  and ensemble techniques  to get better model .Minimized false \\npositives by 90% through rigorous feature engineering and hyperparameter tuning processes with 98% accuracy and \\n100% precision score in spam detection . \\n• Bank Loan Analysis Dashboard  (Nov 2023 ): Created dynamic and user -friendly PowerBI dashboard to provide \\ndetailed insights into loan data, borrower profiles, and loan performance metrics.Dashboard integrates various \\nvisualizations and interactive elements to facilitate comprehensive data analysis. Supporting informed decision -making \\nand improving the overall loan management process by 50%.  \\n \\nAwards and Certificates  \\n• Google Data Analytics Specialization (Coursera)  \\n• Data Science And Machine Learning Specialization (C ampus -X) \\nSkills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sh']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = ['sh']\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sh'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sh', 'ja', 'ka']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x0000018ECFA6D180>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Open the CSV file\n",
    "with open(r\"D:\\AIML_PROGRAMS\\play_tennis.csv\", mode='r', newline='') as file:\n",
    "    # Create a CSV reader object\n",
    "    reader = csv.reader(file)\n",
    "    \n",
    "    # Iterate over each row in the CSV file\n",
    "    for row in reader:\n",
    "        # Join the row's elements into a single string with commas separating the values\n",
    "        line = ', '.join(row)\n",
    "        # Print the line\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
